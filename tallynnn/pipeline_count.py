"""===========================
Pipeline count
===========================

Overview
========

The aim of this pipeline is to take a nanopore input fastq and then process
the file so a counts matrix is generated for downstream differential expression.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_cat_fastq.py config

Input files
-----------

fastq.gz file of nanopore reads that have been sequenced with trimers at
the 5' and 3' end. Data should be added to the data.dir folder.

Pipeline output
===============

A counts matrix with sample as columns and rows as either transcripts or genes. 


Code
====

"""
import sys
import os
import pysam
import pandas as pd
from ruffus import *
import cgatcore.iotools as iotools
import cgatcore.pipeline as P
import cgatcore.experiment as E
from cgatcore.pipeline import cluster_runnable

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])


SEQUENCESUFFIXES = ("*.fastq.gz")

FASTQTARGET = tuple([os.path.join("data.dir/", suffix_name)
                       for suffix_name in SEQUENCESUFFIXES])


def merge_feature_data(infiles):
    '''will merge all of the input files'''

    final_df = pd.DataFrame()
    for infile in infiles:
        name = infile.replace(".counts.tsv.gz", "")
        tmp_df = pd.read_table(infile, sep="\t", header=0, names=["transcript_name", name], index_col=0)
        final_df = final_df.merge(tmp_df, how="outer", left_index=True, right_index=True)

    return final_df


@transform(FASTQTARGET,
         regex("data.dir/(\S+).fastq.gz"),
         r"\1_polyA.fastq.gz")
def polya_correct(infile, outfile):
    '''filter less than 300 bp reads and then make sure polyA is in correct orientation'''

    PYTHON_ROOT = os.path.join(os.path.dirname(__file__), "python/")

    statement = '''python %(PYTHON_ROOT)s/complement_polyA.py --infile=%(infile)s --outname=%(outfile)s'''

    P.run(statement)

@transform(polya_correct,
         regex("(\S+)_polyA.fastq.gz"),
         r"\1_tso_UMI.fastq.gz")
def tso_umi(infile, outfile):
    '''Identify the tso umi for each read'''

    PYTHON_ROOT = os.path.join(os.path.dirname(__file__), "python/")

    statement = '''python %(PYTHON_ROOT)s/tso_umi.py --infile=%(infile)s --outname=%(outfile)s'''

    P.run(statement)


@transform(tso_umi,
         regex("(\S+)_tso_UMI.fastq.gz"),
         r"\1_tso_polya_UMI.fastq.gz")
def polya_umi(infile, outfile):
    '''Identify the polya umi for each read'''

    PYTHON_ROOT = os.path.join(os.path.dirname(__file__), "python/")

    # at the moment im not capturing both ends of the UMI only TSO
    statement = '''cp %(infile)s %(outfile)s'''

    #statement = '''python %(PYTHON_ROOT)s/polya_umi.py --infile=%(infile)s --outname=%(outfile)s'''

    P.run(statement)


@transform(polya_umi,
           regex("(\S+)_tso_polya_UMI.fastq.gz"),
           r"\1_tso_polya_UMI.sam")
def mapping_trans(infile, outfile):
    '''map using minimap2 for the transcripts'''

    statement = '''minimap2 -ax map-ont -p 0.9 --end-bonus 10 -N 3 %(cdna_fasta)s %(infile)s  > %(outfile)s 2> %(outfile)s.log'''

    P.run(statement)

@transform(mapping_trans,
           regex("(\S+)_tso_polya_UMI.sam"),
           r"\1_final_sorted.bam")
def samtools(infile, outfile):
    '''run samtools on the output and index'''

    name = outfile.replace("_final_sorted.bam", "")

    statement = '''samtools view -bS %(infile)s > %(name)s_final.bam && 
                   samtools sort %(name)s_final.bam -o %(name)s_final_sorted.bam && 
                   samtools index %(name)s_final_sorted.bam '''

    P.run(statement)


@transform(samtools,
           regex("(\S+)_final_sorted.bam"),
           r"\1_XT.bam")
def xt_tag(infile, outfile):
    '''add XT tag to the samfile'''

    PYTHON_ROOT = os.path.join(os.path.dirname(__file__), "python/")

    statement = '''python %(PYTHON_ROOT)s/add_XT.py --infile=%(infile)s --outname=%(outfile)s && samtools index %(outfile)s'''

    P.run(statement)

    
@transform(xt_tag,
           regex("(\S+)_XT.bam"),
           r"\1.counts.tsv.gz")
def count_trans(infile, outfile):
    '''Use umi-tools to collapse UMIs and generate counts table'''

    statement = '''umi_tools count --per-gene --gene-tag=XT -I %(infile)s -S %(outfile)s'''

    P.run(statement)


@merge(count_trans, "counts.tsv.gz")
def merge_count(infiles, outfile):
    '''merge counts from ech sample into one'''

    df = merge_feature_data(infiles)
    df = df.fillna(0)
    df.to_csv(outfile, sep="\t", compression="gzip")


#############################
## Gene level analysis ######
#############################

@transform(polya_umi,
           regex("(\S+)_tso_polya_UMI.fastq.gz"),
           r"\1_gene.sam")
def mapping_gene(infile, outfile):
    '''map using minimap2 for the geness'''

    statement = '''minimap2 -ax splice --split-prefix=tmp -k 14 -uf --sam-hit-only --secondary=no --junc-bed hg38-mm10.bed hg38-mm10.fa %(infile)s > %(outfile)s '''

    P.run(statement)




@follows(merge_count)
def full():
    pass


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))    
